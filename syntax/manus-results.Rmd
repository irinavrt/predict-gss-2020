---
title: "Predicting how the U.S. public opinion on moral issues will change from 2018 to 2020 and beyond"
author: "Pontus Strimling, Irina Vartanova, Kimmo Eriksson"
output:
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.width = 6, fig.height = 4, 
                      out.width = "60%", fig.align = 'center',
                      dpi = 300, dev="jpeg", tidy = TRUE)

library(tidyverse)
library(kableExtra)

gss_aggr <- read_rds("../data/gss-issp-trends-to-predict.rds")
mf_data <- read_rds("../data/gss-issp-aa-measures.rds")
sample <- read_rds("../data/for-sample-description.rds")

gss_aggr <- left_join(gss_aggr, mf_data)


inv_logit <- inv_logit <- function(log_odds){
  exp(log_odds)/(1 + exp(log_odds))
}

```

## 2.1 Measuring the argument advantage of a moral opinion

```{r arg_sample}

mf_data <- mf_data %>% 
  filter(issue %in% gss_aggr$issue)

new_issues <- mf_data$issue[mf_data$version == "new issues"]

length(new_issues)

sample_sub <- sample %>% 
 filter(issue %in% new_issues)

sample_sub %>%
  count(issue) %>% 
  summarise(min(n), max(n), mean(n), sum(n))

sample_sub %>% 
  mutate(age = as.numeric(age)) %>% 
  summarise(mean(age), sd(age), 
            mean(sex == "Female", na.rm = TRUE))

sample_sub %>% 
  mutate(age = as.numeric(age),
         polviews = as.numeric(polviews),
         polviews = cut(polviews, c(-1, 3, 6, 10))) %>% 
  count(polviews) %>% 
  mutate(n/sum(n))

sample_sub %>% 
  group_by(id, sex, age, polviews) %>% 
  summarise(n = n(), .groups = "drop") %>% 
  count(n)

sample_sub %>% 
  group_by(id, sex, age, polviews) %>% 
  summarise(n = n(), .groups = "drop") %>% 
  mutate(age = as.numeric(age)) %>% 
  summarise(n_distinct(id), mean(age), sd(age), 
            mean(sex == "Female", na.rm = TRUE))

```

## 2.2 Forecasting shifts of public opinion on moral issues


```{r fig1, fig.cap=pass_caption}

pl_spkhomo <- gss_aggr %>% 
  filter(issue == "spkhomo") %>% 
  # make explicit missing years
  full_join(expand_grid(issue = "spkhomo", 
                        year = 1973:2018)) %>% 
  arrange(year) %>% 
  mutate(log_odds = log(mean_opin/(1 - mean_opin)),
         c_trend = (last(log_odds) - first(log_odds))/((last(year) - first(year))),
         pred_log_odds = first(log_odds) + c_trend*(0:(n()-1)),
         error = log_odds - pred_log_odds,
         pred = inv_logit(pred_log_odds))

c_i <- unique(pl_spkhomo$c_trend)
sq_errors <- pl_spkhomo$error^2
sq_errors <- sq_errors[!is.na(sq_errors)]
error_sd <- sqrt(sum(sq_errors)/(length(sq_errors)-3))

pass_caption <- sprintf(
  "Figure 1. Public opinion change generated by models with a constant positive effect of argument advantage, with (solid) or without (dashed) random error terms. Parameter values: c_i = %.2f, e_i,t N(0, %.2f)",
  c_i, error_sd)

pl_spkhomo %>% 
  ggplot(aes(year, mean_opin))+
  geom_line(data = drop_na(pl_spkhomo)) +
  geom_line(aes(y = pred), linetype = 2) +
  theme_classic() +
  scale_color_viridis_d() +
  scale_x_continuous(expand = expansion(mult = c(0.05, .07)),
                     breaks = seq(1970, 2020, by = 10)) +
  labs(x = NULL, y = "Public opinion") +
  theme(legend.position = c(.8, .2))

# ggsave("fig1_example-issue.jpeg", width = 6, height = 4, dpi = 350)

```

## 2.3 Assessment of the forecasting models using existing data


```{r create_fc}

# Transform public opinion variable.

gss_aggr <- gss_aggr %>%
  mutate(log_odds = log(mean_opin/(1 - mean_opin)))

# Select issues for training set
# that were measured in 2018 and at least twice before that.

issues_18 <- gss_aggr %>% 
  group_by(issue) %>% 
  filter(n() > 2, year == 2018) %>% 
  pull(issue)

# Create training and test sets.

gss_ts_expand <- gss_aggr %>%
  filter(issue %in% issues_18) %>% 
  expand_grid(last_year = seq(2010, 2016, by = 2))

train_ts <- gss_ts_expand %>% 
  filter(year <= last_year) 
test_ts <- gss_ts_expand %>% 
  filter(year == 2018) 

# Estimate drift parameter c_trend (by two year shift).

train_drift <- train_ts %>%
  group_by(last_year, issue, aa) %>% 
  summarise(last_mean_opin = last(mean_opin),
            last_log_odds = last(log_odds),
            c_trend = (last(log_odds) - first(log_odds))/((last(year) - first(year))/2))

# Estimate c_aa based on the relationship between c_trend and aa.

train_fit_pr <- train_drift %>%
  group_by(last_year) %>%
  mutate(c_aa = predict(lm(c_trend ~ aa, cur_data())))

# Make the forecasts.

test_fc <- train_fit_pr %>% 
  inner_join(test_ts) %>% 
  group_by(last_year, issue) %>% 
  mutate(steps = (year - last_year)/2,
         fc_benchmark = last_log_odds,
         fc_trends = last_log_odds + c_trend*steps,
         fc_aa = last_log_odds + c_aa*steps) %>% 
  ungroup()

test_fc %>% 
  summarise(n_issues = n_distinct(issue))

```


```{r accuracy}



accuracy <- test_fc %>% 
  gather(method, forecast, starts_with("fc_")) %>% 
  mutate(error = mean_opin - inv_logit(forecast)) %>% 
  group_by(last_year, method) %>% 
  summarise(MAE = mean(abs(error)),
            RMSE = sqrt(mean(error^2)))

accuracy %>% 
  select(-RMSE) %>% 
  mutate(time_span = 2018 - last_year, 
         time_span = paste(time_span, "years"),
         method = fct_relevel(method, "fc_benchmark", "fc_trends")) %>% 
  group_by(method, time_span) %>% 
  summarise(MAE = round(MAE*100, 1)) %>% 
  spread(method, MAE) %>% 
  mutate(ratio = fc_aa*100/fc_benchmark, 
         ratio = paste0(round(ratio), "%")) %>% 
  mutate_at(vars(fc_benchmark:fc_trends), ~sprintf("%.1f", .)) %>% 
  arrange(desc(time_span)) %>% 
  kbl(col.names = c("Time span of forecast", 
                    "Benchmark", 
                    "Trends", 
                    "AA", 
                    "Ratio AA: benchmark"),
      caption = "Table 1. 2018 point forecast accuracy: mean absolute error in percentage points for different prediction methods and forecasting time spans.") %>% 
  kableExtra::kable_classic()

```
# 3. Predictions

```{r fig2, fig.width = 6, fig.height = 7, fig.cap = "Figure 2. The change from 2010 to 2018 in the popularity of 60 moral opinions in the United States estimated from GSS polls (green arrows) and predicted from argument advantage measures (black arrows). The opinions are labeled by the corresponding variables in the GSS dataset."}

pl_data <- test_fc %>% 
  filter(last_year == 2010) %>% 
  mutate(forecast = inv_logit(fc_aa)) %>% 
  select(issue, aa, forecast, actual_value = mean_opin, last_mean_opin) %>%   gather(type, value, actual_value, forecast) %>% 
  mutate(issue = fct_reorder(issue, last_mean_opin), 
         type = ifelse(type == "actual_value", "True change", "Predicted change")) 

pl_data %>% 
  ggplot(aes(issue))+ 
  geom_segment(aes(xend = issue, y = last_mean_opin, yend = value, 
                   color = type), 
               data = filter(pl_data, type == "True change"),
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre",
               size = .6, 
               position = position_nudge(y = 0, x = 0.2)) +
  geom_segment(aes(xend = issue, y = last_mean_opin, yend = value, 
                   color = type), 
               data = filter(pl_data, type == "Predicted change"),
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre",
               size = .6, 
               position = position_nudge(y = 0, x = -0.2)) +
    coord_flip() +
  theme_bw() +
#  theme(legend.position = c(.8, .2)) +
  scale_color_viridis_d(end = 0.85) +
  labs(x = NULL, y = "Forecast", color = NULL) 

#ggsave("fig2_forecast.jpeg", width = 6, height = 7, dpi = 350)

```

```{r fc_2020}

# Estimate drift parameter c_trend (by two year shift).

gss_drift <- gss_aggr %>%
  group_by(issue, aa) %>% 
  summarise(n = n(), 
            last_year = last(year),
            last_mean_opin = last(mean_opin),
            last_log_odds = last(log_odds),
            c_trend = (last(log_odds) - first(log_odds))/((last(year) - first(year))/2), 
            .groups = "drop") %>% 
  mutate(c_trend = ifelse(n == 1, NA_real_, c_trend))

m <- lm(c_trend ~ aa, gss_drift)

# Estimate c_aa based on the relationship between c_trend and aa.

gss_aa <- gss_drift %>%
  mutate(c_aa = predict(m, newdata = .))

# Make the forecasts.

gss_fc <- gss_aa %>% 
  expand_grid(fc_year = seq(2020, 2030, by = 2)) %>% 
  mutate(steps = (fc_year - last_year)/2,
         fc_aa = last_log_odds + c_aa*steps,
         forecast = inv_logit(fc_aa)) 

gss_fc %>% 
  left_join(mf_data %>% select(issue, wording)) %>% 
  mutate(wording = ifelse(issue %in% new_issues, 
                          paste0(wording, "*"),
                          wording)) %>% 
  transmute(wording, issue, aa, fc_year, 
            last_opin = sprintf("%.2f (%.0f)",
                                last_mean_opin,
                                last_year) ,
            forecast = sprintf("%.2f", forecast)) %>% 
  spread(fc_year, forecast) %>% 
  arrange(desc(aa)) %>% 
  kbl(col.names = c("Item", "GSS code", "AA",
                    "Latest public opinion",
                    "Forecast 2020",
                    "Forecast 2022",
                    "Forecast 2024",
                    "Forecast 2026",
                    "Forecast 2028",
                    "Forecast 2030"),
      digits = 2) %>% 
  kable_classic()

```

