---
title: "Predicting how the U.S. public opinion on moral issues will change from 2018 to 2020 and beyond"
author: "Pontus Strimling, Irina Vartanova, Kimmo Eriksson"
output:
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.width = 6, fig.height = 4, 
                      out.width = "60%", fig.align = 'center',
                      dpi = 300, dev="jpeg", tidy = TRUE)

library(tidyverse)
library(furrr)
library(broom)
library(kableExtra)

gss_aggr <- read_rds("../data/gss-issp-trends-to-predict.rds")
mf_data <- read_rds("../data/gss-issp-aa-measures.rds")
sample <- read_rds("../data/for-sample-description.rds")

gss_aggr <- left_join(gss_aggr, mf_data)

# Transform public opinion variable.
gss_aggr <- gss_aggr %>%
  mutate(log_odds = log(mean_opin/(1 - mean_opin)))


# for bootstrapping sampling error
gss_2018 <- read_rds("../data/gss-issp-individual-data-2018.rds")

inv_logit <- inv_logit <- function(log_odds){
  exp(log_odds)/(1 + exp(log_odds))
}

```

## 2.1 Measuring the argument advantage of moral opinions

```{r arg_sample}

sample %>%
  count(issue) %>% 
  summarise(min(n), max(n), mean(n), sum(n))

sample %>% 
  mutate(age = as.numeric(age)) %>% 
  summarise(mean(age), sd(age), 
            mean(sex == "Female", na.rm = TRUE))

```

## 2.2 Forecasting shifts of public opinion on moral issues


```{r fig1, fig.cap=pass_caption}

pl_spkhomo <- gss_aggr %>% 
  filter(issue == "spkhomo") %>% 
  # make explicit missing years
  full_join(expand_grid(issue = "spkhomo", 
                        year = 1973:2018)) %>% 
  arrange(year) %>% 
  mutate(log_odds = log(mean_opin/(1 - mean_opin)),
         c_trend = (last(log_odds) - first(log_odds))/((last(year) - first(year))),
         pred_log_odds = first(log_odds) + c_trend*(0:(n()-1)),
         error = log_odds - pred_log_odds,
         pred = inv_logit(pred_log_odds))

c_i <- unique(pl_spkhomo$c_trend)
sq_errors <- pl_spkhomo$error^2
sq_errors <- sq_errors[!is.na(sq_errors)]
error_var <- sum(sq_errors)/(length(sq_errors)-3)

pass_caption <- sprintf(
  "Figure 1. Public opinion change generated by models with a constant positive effect of argument advantage, with (solid) or without (dashed) random error terms. Parameter values: c_i = %.2f, e_i,t N(0, %.2f)",
  c_i, error_var)

pl_spkhomo %>% 
  ggplot(aes(year, mean_opin))+
  geom_line(data = drop_na(pl_spkhomo)) +
  geom_line(aes(y = pred), linetype = 2) +
  theme_classic() +
  scale_color_viridis_d() +
  scale_x_continuous(expand = expansion(mult = c(0.05, .07)),
                     breaks = seq(1970, 2020, by = 10)) +
  labs(x = NULL, y = "Public opinion") +
  theme(legend.position = c(.8, .2))

# ggsave("fig1_example-issue.jpeg", width = 6, height = 4, dpi = 350)

```

## 2.3 Assessment of the forecasting models using existing data


```{r create_fc}

# Select issues for training set
# that were measured in 2018 and at least twice before that.

issues_18 <- gss_aggr %>% 
  group_by(issue) %>% 
  filter(n() > 2, year == 2018) %>% 
  pull(issue)

# Create training and test sets.

gss_ts_expand <- gss_aggr %>%
  filter(issue %in% issues_18) %>% 
  expand_grid(last_year = seq(2010, 2016, by = 2))

train_ts <- gss_ts_expand %>% 
  filter(year <= last_year) 
test_ts <- gss_ts_expand %>% 
  filter(year == 2018) 

# Estimate drift parameter c_trend (by two year shift).

train_drift <- train_ts %>%
  arrange(last_year, issue, aa) %>% 
  group_by(last_year, issue, aa) %>% 
  summarise(last_mean_opin = last(mean_opin),
            last_log_odds = last(log_odds),
            c_trend = (last(log_odds) - first(log_odds))/((last(year) - first(year))/2))

train_c_aa <- train_drift %>% 
  group_by(last_year) %>%
  mutate(c_aa = predict(lm(c_trend ~ aa, cur_data())))

lm_coefs <- train_drift %>% 
  group_by(last_year) %>%
  summarise(coef = list(tidy(lm(c_trend ~ aa, cur_data())))) %>% 
  unnest(coef)
# Estimate c_aa based on the relationship between c_trend and aa.

train_fit_pr <- train_drift %>%
  group_by(last_year) %>%
  mutate(c_aa = predict(lm(c_trend ~ aa, cur_data())))


# Make the forecasts.

test_fc <- train_fit_pr %>% 
  inner_join(test_ts) %>% 
  group_by(last_year, issue) %>% 
  mutate(steps = (year - last_year)/2,
         fc_benchmark = last_log_odds,
         fc_trends = last_log_odds + c_trend*steps,
         fc_aa = last_log_odds + c_aa*steps) %>%  
  ungroup()

test_fc <- test_fc %>% 
  mutate(across(fc_benchmark:fc_aa, ~inv_logit(.)*100),  
         across(c(last_mean_opin, mean_opin), ~100*.))


```


```{r accuracy}

accuracy <- test_fc %>% 
  group_by(last_year) %>% 
  summarise(across(starts_with("fc"), ~mean((mean_opin - .)^2)))

```


```{r sampling_error}

# Bootstrap GSS 2018 sample for random draws of sampling error

draw_e <- function(i){
  
draw_gss <- gss_2018 %>% 
  sample_n(n(), replace = TRUE) %>% 
  pivot_longer(c(-id, -year, -wgt), 
               names_to = "issue", 
               values_to = "opinion") %>% 
  drop_na(opinion)

draw_aggr <- draw_gss %>% 
  group_by(issue) %>% 
  summarise(mean_opin = weighted.mean(opinion, wgt)) 

left_join(draw_aggr, 
          gss_aggr %>% 
            filter(year == 2018) %>% 
            select(issue, true_mean_opin = mean_opin), 
          by = "issue") %>% 
  transmute(issue, i = i, e = mean_opin - true_mean_opin) %>% 
  mutate(e = e*100)
}

# Use furrr package for parallel computation
plan(multisession, workers = 5)

e_draws <- future_map_dfr(1:500, 
                           draw_e, .options = furrr_options(seed = 1000),
                           .progress = TRUE)

plan(multisession, workers = 1)

test_fc_e <- left_join(test_fc, e_draws)

conf_int_diff <- test_fc_e %>% 
  group_by(i, last_year) %>% 
  summarise(error_bench_diff = mean(2*e*(fc_benchmark - fc_aa)),
            error_trends_diff = mean(2*e*(fc_trends - fc_aa))) %>% 
  group_by(last_year) %>% 
  summarise(bench_diff_lwr = quantile(error_bench_diff, p = 0.025),
            bench_diff_upr = quantile(error_bench_diff, p = 0.975),
            trends_diff_lwr = quantile(error_trends_diff, p = 0.025),
            trends_diff_upr = quantile(error_trends_diff, p = 0.975))
```

```{r tbl1}

# alphas and betas to display in the table

lm_coefs <- lm_coefs %>% 
  select(last_year, term, estimate) %>% 
  pivot_wider(names_from = "term",
              values_from = "estimate") %>% 
  transmute(last_year, 
            coef = sprintf("%.2f, %.2f", `(Intercept)`, aa))

tbl_data <- left_join(lm_coefs, accuracy)
tbl_data <- left_join(tbl_data, conf_int_diff) 

tbl_data <- tbl_data %>% 
  mutate(diff_benchmark = sprintf("%.1f [%.1f, %.1f]",
                                  fc_benchmark - fc_aa,
                                  fc_benchmark - fc_aa + bench_diff_lwr,
                                  fc_benchmark - fc_aa + bench_diff_upr),
         diff_trends = sprintf("%.1f [%.1f, %.1f]",
                                  fc_trends - fc_aa,
                                  fc_trends - fc_aa + trends_diff_lwr,
                                  fc_trends - fc_aa + trends_diff_upr)) %>% 
  select(last_year, coef, fc_benchmark:fc_aa, diff_benchmark, diff_trends) 


tbl_data %>% 
  kbl(col.names = c("Starting point (T)", 
                    "Parameter values alpha_T, beta_T used for predictions from AA", 
                    "MSD_AA", 
                    "MSD_Benchmark", 
                    "MSD_Trends",
                    "MSD_Benchmark - MSD_AA",
                    "MSD_Trends - MSD_AA"),
      digits = 1,
      caption = "Table 1. 2018 point forecast accuracy assessed by the mean squared deviation (MSD) between predicted and observed public opinion in 2018.") %>% 
  kableExtra::kable_classic()

```



```{r fig2, fig.width = 7, fig.height = 7, fig.cap = "Figure 2. The change in the popularity of 63 moral opinions in the United States from 2010 to 2018 as observed in GSS polls (green arrows) and as predicted from argument advantage measures (black arrows). The items are abbreviated in the figure. For the full text of items, see Supplementary Table 1."}

pl_data <- test_fc %>% 
  filter(last_year == 2010) %>% 
  select(issue, aa, forecast = fc_aa, actual_value = mean_opin, last_mean_opin) %>%   gather(type, value, actual_value, forecast) %>% 
  mutate(type = ifelse(type == "actual_value", "True change", "Predicted change")) 

pl_data <- left_join(pl_data, 
                     mf_data %>% select(issue, short_label)) %>% 
  mutate(short_label = fct_reorder(short_label, last_mean_opin))
         

pl_data %>% 
  ggplot(aes(x = short_label, xend = short_label))+ 
  geom_segment(aes(y = last_mean_opin, yend = value, 
                   color = type), 
               data = filter(pl_data, type == "True change"),
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre",
               size = .6, 
               position = position_nudge(y = 0, x = 0.2)) +
  geom_segment(aes(y = last_mean_opin, yend = value, 
                   color = type), 
               data = filter(pl_data, type == "Predicted change"),
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre",
               size = .6, 
               position = position_nudge(y = 0, x = -0.2)) +
  coord_flip() +
  theme_bw() +
  scale_color_viridis_d(end = 0.85) +
  labs(x = NULL, y = "Forecast", color = NULL) 

#ggsave("fig2_forecast.jpeg", width = 7, height = 7, dpi = 350)

```

## 3. Predictions

```{r fc_2020}

# Estimate drift parameter c_trend (by two year shift).

gss_drift <- gss_aggr %>%
  group_by(issue, aa) %>% 
  summarise(n = n(), 
            last_year = last(year),
            last_mean_opin = last(mean_opin),
            last_log_odds = last(log_odds),
            c_trend = (last(log_odds) - first(log_odds))/((last(year) - first(year))/2), 
            .groups = "drop") %>% 
  mutate(c_trend = ifelse(n == 1, NA_real_, c_trend))

m <- lm(c_trend ~ aa, gss_drift)
coef(m)

# Estimate c_aa based on the relationship between c_trend and aa.
gss_aa <- gss_drift %>%
  mutate(c_aa = predict(m, newdata = .))

# Estimate sigma for prediction intervals
# Sigma is averaged across issues
gss_sd <- left_join(gss_aggr, gss_aa) %>%
  arrange(issue) %>% 
  group_by(issue) %>% 
  mutate(yr_lag = (year - lag(year))/2, # year lag for years that were skipped in time series. One step is two years.
         resid_aa = log_odds - (lag(log_odds) + yr_lag*c_aa)) %>% 
  drop_na(resid_aa) %>% 
  summarise(sigma_aa = sqrt(sum(resid_aa^2)/(n() - 2)), 
            n = n()) %>% 
  mutate(sigma_aa = ifelse(n < 3, NA_real_, sigma_aa))

sigma <- sqrt(mean(gss_sd$sigma_aa^2, na.rm = TRUE)) 
  
# Make the forecasts.
gss_fc <- gss_aa %>% 
  expand_grid(fc_year = seq(2018, 2030, by = 2)) %>% 
  mutate(steps = (fc_year - last_year)/2,
         fc_aa = last_log_odds + c_aa*steps,
         forecast = inv_logit(fc_aa), 
         sigma_step = sigma*sqrt(steps), 
         lwr_50 = inv_logit(qnorm(0.25, mean = fc_aa, sd = sigma_step)),
         upr_50 = inv_logit(qnorm(0.75, mean = fc_aa, sd = sigma_step))) 

```


```{r fig3, fig.width=7, fig.height=9.5, caption = "Figure 3. The predicted change in the popularity of 102 moral opinions in the United States from 2018 to 2020, 2022, 2024, 2026, 2028, and 2030. More details are found in Supplementary Table 1."}

pl_data <- gss_fc %>% 
  select(issue, aa, fc_year, forecast) %>% 
  pivot_wider(names_from = fc_year, 
              values_from = forecast)

pl_data <- left_join(pl_data, 
                     mf_data %>% select(issue, short_label)) %>% 
  mutate(short_label = fct_reorder(short_label, `2018`))

pl3 <- pl_data %>% 
  ggplot(aes(short_label))+ 
  geom_segment(aes(xend = short_label, y = `2018`, yend = `2020`), 
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre", size = .6) +
  geom_segment(aes(xend = short_label, y = `2020`, yend = `2022`), 
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre", size = .6) +
  geom_segment(aes(xend = short_label, y = `2022`, yend = `2024`), 
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre", size = .6) +
  geom_segment(aes(xend = short_label, y = `2024`, yend = `2026`), 
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre", size = .6) +
  geom_segment(aes(xend = short_label, y = `2026`, yend = `2028`), 
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre", size = .6) +
  geom_segment(aes(xend = short_label, y = `2028`, yend = `2030`), 
               arrow = arrow(length = unit(0.1, "cm")), 
               lineend = "round",  linejoin = "mitre", size = .6) +
  coord_flip() +
  theme_bw() +
  theme(axis.text.y = element_text(size = 9)) +
  labs(x = NULL, y = "Forecast", color = NULL)
pl3
# ggsave("fig3_forecast.jpeg", pl3, width = 7, height = 9.5, dpi = 350)

```

### Supplementary materials

```{r suppl_table1}

new_issues <- mf_data$version[mf_data$issue == "new issues"]
  
gss_fc %>% 
  filter(fc_year > 2018) %>% 
  left_join(mf_data %>% select(issue, short_label)) %>% 
  mutate(short_label = factor(short_label, 
                              levels = rev(levels(pl_data$short_label)))) %>% 
  arrange(short_label) %>% 
  mutate(short_label = as.character(short_label),
         short_label = ifelse(issue %in% new_issues, 
                          paste0(short_label, "*"),
                          short_label), 
         short_label = factor(short_label, levels = unique(short_label))) %>% 
  transmute(short_label, issue, aa, fc_year, 
            last_opin = sprintf("%.2f (%.0f)",
                                last_mean_opin,
                                last_year) ,
            forecast = sprintf("%.2f [%.2f, %.2f]", forecast, lwr_50, upr_50)) %>% 
  spread(fc_year, forecast) %>% 
#  arrange(desc(aa)) %>% 
  kbl(col.names = c("Item", "GSS code", "AA",
                    "Latest public opinion",
                    "Forecast 2020",
                    "Forecast 2022",
                    "Forecast 2024",
                    "Forecast 2026",
                    "Forecast 2028",
                    "Forecast 2030"),
      digits = 2,
      caption = "Supplementary Table 1. Forecasts with 50% prediction intervals for 2020 to 2030 for GSS items (on moral issues) that were asked within the last 10 years.") %>% 
  kable_classic()

```

```{r suppl_fig2, fig.width = 10, fig.height = 15, fig.cap = "Supplementary Figure 2. Historical trends (black) and forecasts (purple) for 2020 to 2030 with 50% prediction intervals in the popularity of 102 moral opinions in the United States."}

mf_ordered <- mf_data %>% 
  drop_na(short_label) %>% 
  mutate(short_label = factor(short_label, 
                              levels = levels(pl_data$short_label))) %>% 
  arrange(short_label)

gss_aggr <- gss_aggr %>% 
  mutate(issue = factor(issue, levels = mf_ordered$issue)) 

gss_fc <- gss_fc %>% 
  mutate(issue = factor(issue, levels = mf_ordered$issue)) 

pl <- gss_aggr %>% 
  ggplot(aes(year, mean_opin)) +
  geom_line(size = .8) +
  geom_point(data = gss_aggr %>% group_by(issue) %>% filter(n() == 1), size = .8) +
  facet_wrap(~issue, ncol = 6) +
  geom_ribbon(data = filter(gss_fc, fc_year > 2018),
              aes(x = fc_year, y = forecast, ymin = lwr_50, ymax = upr_50), fill = "#CC99FF") +
  geom_line(data = filter(gss_fc, fc_year > 2018),  
            aes(x = fc_year, y = forecast), color = "#663399", size = .8) +
  scale_x_continuous(limits = c(1972, 2030), breaks = seq(1970, 2030, 20)) +
  labs(x = NULL, y = NULL)   +
  theme_bw()
pl
# ggsave("suppl_fig2.jpeg", pl, dpi = 350, width = 10, height = 15)


```
